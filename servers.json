{
  "servers": [
    {
      "id": "5cab8af7-1240-45b4-a58f-5481289f40e0",
      "name": "Test Server",
      "endpoint_url": "http://localhost:1234/v1/chat/completions",
      "model_name": "test-model",
      "status": "inactive",
      "config": {},
      "created_at": "2025-11-05 11:19:58.506542",
      "updated_at": "2025-11-05 11:19:58.506649"
    },
    {
      "id": "5e48536a-55dd-4a92-b90b-94d7bfcce143",
      "name": "Second Server",
      "endpoint_url": "http://localhost:5678/v1/chat/completions",
      "model_name": "second-model",
      "status": "inactive",
      "config": {},
      "created_at": "2025-11-05 11:20:58.215157",
      "updated_at": "2025-11-05 11:20:58.215324"
    },
    {
      "id": "eb75e115-8421-408b-ac16-eaa97fed0727",
      "name": "tinyllama-test",
      "model_name": "tinyllama",
      "status": "inactive",
      "mode": "self-hosted",
      "endpoint_url": null,
      "model_path": "/Users/van/.cache/py_llm_hosting/models/models--TheBloke--TinyLlama-1.1B-Chat-v1.0-GGUF/snapshots/52e7645ba7c309695bec7ac98f4f005b139cf465/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
      "backend_type": "llama-cpp",
      "backend_config": {
        "n_gpu_layers": 0
      },
      "config": {},
      "created_at": "2025-11-05 11:46:03.145387",
      "updated_at": "2025-11-05 11:46:03.145547"
    },
    {
      "id": "a9a08fe5-bb3e-40a7-9604-f12a7344056b",
      "name": "qwen-mlx",
      "model_name": "qwen2.5-0.5b",
      "status": "inactive",
      "mode": "self-hosted",
      "endpoint_url": null,
      "model_path": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "backend_type": "mlx",
      "backend_config": {},
      "config": {},
      "created_at": "2025-11-05 12:00:06.698239",
      "updated_at": "2025-11-05 12:00:06.698376"
    }
  ],
  "mcp_sessions": []
}