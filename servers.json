{
  "servers": [
    {
      "id": "eb75e115-8421-408b-ac16-eaa97fed0727",
      "name": "tinyllama-test",
      "model_name": "tinyllama",
      "status": "active",
      "mode": "self-hosted",
      "endpoint_url": null,
      "model_path": "/Users/van/.cache/py_llm_hosting/models/models--TheBloke--TinyLlama-1.1B-Chat-v1.0-GGUF/snapshots/52e7645ba7c309695bec7ac98f4f005b139cf465/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
      "backend_type": "llama-cpp",
      "backend_config": {
        "n_gpu_layers": 0
      },
      "config": {},
      "created_at": "2025-11-05 11:46:03.145387",
      "updated_at": "2025-11-05 12:59:53.467806"
    },
    {
      "id": "a9a08fe5-bb3e-40a7-9604-f12a7344056b",
      "name": "qwen-mlx",
      "model_name": "qwen2.5-0.5b",
      "status": "active",
      "mode": "self-hosted",
      "endpoint_url": null,
      "model_path": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "backend_type": "mlx",
      "backend_config": {},
      "config": {},
      "created_at": "2025-11-05 12:00:06.698239",
      "updated_at": "2025-11-05 13:01:44.229024"
    }
  ],
  "mcp_sessions": []
}